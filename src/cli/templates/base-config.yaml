name: {{ name | default("default", true) }}

global:
  DATA_PATH: "{{ global.DATA_PATH | default('/root/data/', true) }}"
  ACCOUNTS_PATH: "{{ global.ACCOUNTS_PATH | default('/root/.accounts/', true) }}"
  ACCEPTED_FILES:
    {%- for file_type in global.ACCEPTED_FILES | default(['.txt', '.html', '.pdf']) %}
    - "{{ file_type }}"
    {%- endfor %}
  LOGGING:
    input_output_filename: "{{ global.LOGGING.input_output_filename | default('chain_input_output.log', true) }}"
  verbosity: {{ verbosity | default(3, true) }}

services:
  benchmarking:
    out_dir: {{ services.benchmarking.out_dir | default(".", true) }}
    queries_path: {{ services.benchmarking.queries_path | default("queries", true) }}
    modes:
      {%- for mode in services.benchmarking.modes | default(["SOURCES", "RAGAS"]) %}
      - {{ mode }}
      {%- endfor %}
    mode_settings:
      sources_settings:
        default_match_field: {{ services.benchmarking.mode_settings.sources_settings.default_match_field | default("file_name", true) }} # metadata field to check for source matching
      ragas_settings: 
        enabled_metrics:
          {%- for metric in services.benchmarking.ragas_settings.enabled_metrics | default(["answer_relevancy", "faithfulness", "context_precision", "context_recall"]) %}
          - {{ metric }}
          {%- endfor %}
        provider: {{ services.benchmarking.mode_settings.ragas_settings.provider | default("OpenAI", True)}} # supports OpenAI, Ollama, HuggingFace, and Anthropic
        evaluation_model_settings:
          {%- set provider = services.benchmarking.mode_settings.ragas_settings.provider | default("OpenAI") %}
          {%- set default_models = {
              "OpenAI": "gpt-4",
              "Ollama": "gemma3",
              "HuggingFace": "Qwen/Qwen2.5-7B-Instruct-1M",
              "Anthropic": "claude-3-sonnet-20240229"
          } %}
          {%- if services.benchmarking.mode_settings.ragas_settings.evaluation_model_settings.model_name %}
          model_name: {{ services.benchmarking.mode_settings.ragas_settings.evaluation_model_settings.model_name }}
          {%- else %}
          model_name: {{ default_models.get(provider, "gpt-4") }}
          {%- endif %}
          base_url: {{ services.benchmarking.mode_settings.ragas_settings.evaluation_model_settings.base_url | default("", True) }} # for Ollama support
        embedding_model: {{ services.benchmarking.mode_settings.ragas_settings.embedding_model | default("OpenAI", true) }}
        timeout: {{ services.benchmarking.mode_settings.ragas_settings.timeout | default(180, true) }}
        batch_size: {{ services.benchmarking.mode_settings.ragas_settings.batch_size | default(false, true) }}


  piazza:
    network_id: {{ services.piazza.network_id }}
    update_time: {{ services.piazza.update_time | default(60, true) }}
  mattermost:
    update_time: {{ services.mattermost.update_time | default(60, true) }}
  redmine_mailbox:
    pipeline: {{ services.redmine_mailbox.pipeline | default('CMSCompOpsAgent', true) }}
    url: {{ services.redmine_mailbox.url | default('', true) }}
    project: {{ services.redmine_mailbox.project | default('', true) }}
    redmine_update_time: {{ services.redmine_mailbox.redmine_update_time | default(10, true) }}
    answer_tag: {{ services.redmine_mailbox.answer_tag | default('-- archi -- Resolving email was sent', true) }}
    imap4_port: {{ services.redmine_mailbox.imap4_port | default(143, true) }}
    mailbox_update_time: {{ services.redmine_mailbox.mailbox_update_time | default(10, true) }}
  postgres:
    port: {{ services.postgres.port | default(5432, true) }}
    user: {{ services.postgres.user | default('archi', true) }}
    database: {{ services.postgres.database | default('archi-db', true) }}
    host: {{ 'localhost' if host_mode else (utils.postgres.host | default('postgres', true)) }}
  chat_app:
    pipeline: {{ services.chat_app.pipeline | default("QAPipeline", true) }}
    trained_on: {{ services.chat_app.trained_on | default("No description provided.", true) }} # leaving for now for backwards compatibility can remove later
    port: {{ services.chat_app.port | default(7861, true) }}
    external_port: {{ services.chat_app.external_port | default(7861, true) }}
    host: {{ services.chat_app.host | default("0.0.0.0", true) }}
    hostname: {{ services.chat_app.hostname | default("localhost", true) }}
    template_folder: "{{ services.chat_app.template_folder | default('/root/archi/src/interfaces/chat_app/templates', true) }}"
    static_folder: "{{ services.chat_app.static_folder | default('/root/archi/src/interfaces/chat_app/static', true) }}"
    num_responses_until_feedback: {{ services.chat_app.num_responses_until_feedback | default(3, true) }}
    include_copy_button: {{ services.chat_app.include_copy_button | default(false, true) }}
    flask_debug_mode: {{ services.chat_app.flask_debug_mode | default(true, false) }}
    auth:
      enabled: {{ services.chat_app.auth.enabled | default(false, true) }}
      sso:
        enabled: {{ services.chat_app.auth.sso.enabled | default(false, true) }}
        server_metadata_url: {{ services.chat_app.auth.sso.server_metadata_url | default("", true) }}
        authorize_url: {{ services.chat_app.auth.sso.authorize_url | default("", true) }}
        client_kwargs:
          scope: {{ services.chat_app.auth.sso.client_kwargs.scope | default("openid profile email", true) }}
      basic:
        enabled: {{ services.chat_app.auth.basic.enabled | default(false, true) }}
      {% if services.chat_app.auth.auth_roles is defined %}
      auth_roles: {{ services.chat_app.auth.auth_roles | tojson }}
      {% endif %}
  data_manager:
    auth:
      enabled: {{ services.data_manager.auth.enabled | default(true, true) }}
      api_token: "{{ services.data_manager.auth.api_token | default('', true) }}"
    enabled: {{ services.data_manager.enabled | default(true, true) }}
    port: {{ services.data_manager.port | default(7871, true) }}
    external_port: {{ services.data_manager.external_port | default(7871, true) }}
    host: {{ services.data_manager.host | default("0.0.0.0", true) }}
    hostname: {{ services.data_manager.hostname | default('host.containers.internal' if host_mode else 'data-manager', true) }}
    template_folder: "{{ services.data_manager.template_folder | default('/root/archi/src/interfaces/chat_app/templates', true) }}"
    static_folder: "{{ services.data_manager.static_folder | default('/root/archi/src/interfaces/chat_app/static', true) }}"
    flask_debug_mode: {{ services.data_manager.flask_debug_mode | default(false, true) }}
  grader_app:
    port: {{ services.grader_app.port | default(7861, true) }}
    external_port: {{ services.grader_app.external_port | default(7862, true) }}
    host: {{ services.grader_app.host | default("0.0.0.0", true) }}
    hostname: {{ services.grader_app.hostname | default("localhost", true) }}
    template_folder: "{{ services.grader_app.template_folder | default('/root/archi/src/interfaces/grader_app/templates', true) }}"
    num_problems: {{ services.grader_app.num_problems | default(1, true) }}
    local_rubric_dir: "{{ services.grader_app.local_rubric_dir }}"
    local_users_csv_dir: "{{ services.grader_app.local_users_csv_dir }}"
    flask_debug_mode: {{ services.grader_app.flask_debug_mode | default(true, false) }}
  vectorstore:
    # PostgreSQL with pgvector is the storage backend
    backend: postgres
    # Distance metric for similarity search: "cosine", "l2", "inner_product"
    distance_metric: {{ services.vectorstore.distance_metric | default('cosine', true) }}
  grafana:
    port: {{ services.grafana.port | default(3000, true) }}
    external_port: {{ services.grafana.external_port | default(3000, true) }}

data_manager:
  collection_name: {{ collection_name | default("default_collection", true) }}
  embedding_name: {{ data_manager.embedding_name | default('OpenAIEmbeddings', true) }}
  embedding_class_map:
    OpenAIEmbeddings:
      class: OpenAIEmbeddings
      kwargs:
        model: {{ data_manager.embedding_class_map.OpenAIEmbeddings.kwargs.model | default('text-embedding-3-small', true) }}
      similarity_score_reference: {{ data_manager.embedding_class_map.OpenAIEmbeddings.similarity_score_reference | default(10, true) }}
    HuggingFaceEmbeddings:
      class: HuggingFaceEmbeddings
      kwargs:
        model_name: {{ data_manager.embedding_class_map.HuggingFaceEmbeddings.kwargs.model_name | default('sentence-transformers/all-MiniLM-L6-v2', true) }}
        model_kwargs:
          device: {{ data_manager.embedding_class_map.HuggingFaceEmbeddings.kwargs.model_kwargs.device | default('cpu', true) }}
        encode_kwargs:
          normalize_embeddings: {{ data_manager.embedding_class_map.HuggingFaceEmbeddings.kwargs.encode_kwargs.normalize_embeddings | default(true, true) }}
      similarity_score_reference: {{ data_manager.embedding_class_map.HuggingFaceEmbeddings.similarity_score_reference | default(10, true) }}
      query_embedding_instructions: {{ data_manager.embedding_class_map.HuggingFaceEmbeddings.query_embedding_instructions | default("null", true) }}
  chunk_size: {{ data_manager.chunk_size | default(1000, true) }}
  chunk_overlap: {{ data_manager.chunk_overlap | default(0, true) }}
  parallel_workers: {{ data_manager.parallel_workers | default(32, true) }}
  reset_collection: {{ data_manager.reset_collection | default(true, true) }}
  stemming:
    enabled: {{ data_manager.stemming.enabled | default(false, true) }}
  distance_metric: {{ data_manager.distance_metric | default('cosine', true) }}
  retrievers:
    semantic_retriever:
      num_documents_to_retrieve: {{ data_manager.retrievers.semantic_retriever.num_documents_to_retrieve | default(5, true) }}
    bm25_retriever:
      num_documents_to_retrieve: {{ data_manager.retrievers.bm25_retriever.num_documents_to_retrieve | default(5, true) }}
    hybrid_retriever:
      num_documents_to_retrieve: {{ data_manager.retrievers.hybrid_retriever.num_documents_to_retrieve | default(5, true) }}
      bm25_weight: {{ data_manager.retrievers.hybrid_retriever.bm25_weight | default(0.6, true) }}
      semantic_weight: {{ data_manager.retrievers.hybrid_retriever.semantic_weight | default(0.4, true) }}
  sources:
    local_files:
      enabled: {{ data_manager.sources.local_files.enabled | default(true, true) }}
      visible: {{ data_manager.sources.local_files.visible | default(true, true) }}
      schedule: '{{ data_manager.sources.local_files.schedule | default("", true) }}'
      paths:
        {%- set paths = data_manager.sources.local_files.paths | default([], true) %}
        {%- for path in paths %}
        - {{ path }}
        {%- endfor %}
    links:
      base_source_depth: {{ data_manager.sources.links.base_source_depth | default(1, true) }}
      max_pages: {{ data_manager.sources.links.max_pages | default(null, true) }}
      enabled: {{ data_manager.sources.links.enabled | default(true, true) }}
      visible: {{ data_manager.sources.links.visible | default(true, true) }}
      schedule: '{{ data_manager.sources.links.schedule | default("", true) }}'
      input_lists:
        {%- set link_lists = data_manager.sources.links.input_lists | default([], true) %}
        {%- for input_list in link_lists %}
        - {{ input_list }}
        {%- endfor %}
      html_scraper:
        reset_data: {{ data_manager.sources.links.html_scraper.reset_data | default(true, true) }}
        verify_urls: {{ data_manager.sources.links.html_scraper.verify_urls | default(false, true) }}
        enable_warnings: {{ data_manager.sources.links.html_scraper.enable_warnings | default(false, true) }}
      selenium_scraper:
        enabled: {{ data_manager.sources.links.selenium_scraper.selenium_scraper.enabled | default(false, True) }}
        visible: {{ data_manager.sources.links.selenium_scraper.selenium_scraper.visible | default(false, true) }}
        use_for_scraping: {{ data_manager.sources.links.selenium_scraper.use_for_scraping | default(false, true) }}
        selenium_class: {{  data_manager.sources.links.selenium_scraper.selenium_class | default('CERNSSOScraper', true)  }}
        selenium_class_map:
          CERNSSOScraper:
            class: {{ data_manager.sources.links.selenium_scraper.selenium_class_map.CERNSSOScraper.class | default('CERNSSOScraper', true) }}
            kwargs:
              headless:  {{ data_manager.sources.links.selenium_scraper.selenium_class_map.CERNSSOScraper.kwargs.headless | default(true, true) }}
    git:
      enabled: {{ data_manager.sources.git.enabled | default(true, true) }}
      visible: {{ data_manager.sources.git.visible | default(true, true) }}
      schedule: '{{ data_manager.sources.git.schedule | default("", true) }}'
    sso:
      enabled: {{ data_manager.sources.sso.enabled | default(true, true) }}
      visible: {{ data_manager.sources.sso.visible | default(true, true) }}
      schedule: '{{ data_manager.sources.sso.schedule | default("", true) }}'
    jira:
      enabled: {{ data_manager.sources.jira.enabled | default(true, true) }}
      url: {{ data_manager.sources.jira.url | default('', true) }}
      visible: {{ data_manager.sources.jira.visible | default(true, true) }}
      schedule: '{{ data_manager.sources.jira.schedule | default("", true) }}'
      projects:
        {%- for project in data_manager.sources.jira.projects | default([], true) %}
        - {{ project }}
        {%- endfor %}
      anonymize_data: {{ data_manager.sources.jira.anonymize_data | default(false, true) }}
      max_tickets: {{ data_manager.sources.jira.max_tickets | default(1e10, true) }}
      cutoff_date: {{ data_manager.sources.jira.cutoff_date | default('', true) }}
    redmine:
      enabled: {{ data_manager.sources.redmine.enabled | default(true, true) }}
      url: {{ data_manager.sources.redmine.url | default('', true) }}
      projects:
        {%- for project in data_manager.sources.redmine.projects | default([], true) %}
        - {{ project }}
        {%- endfor %}
      visible: {{ data_manager.sources.redmine.visible | default(false, true) }}
      schedule: '{{ data_manager.sources.redmine.schedule | default("", true) }}'
      anonymize_data: {{ data_manager.sources.redmine.anonymize_data | default(true, true) }}
  utils:
    anonymizer:
        nlp_model: {{ data_manager.utils.anonymizer.nlp_model | default('en_core_web_sm', true) }}
        excluded_words:
          {%- for word in data_manager.utils.anonymizer.excluded_words | default([], true) %}
          - {{ word }}
          {%- endfor %}
        greeting_patterns:
          {%- for pattern in data_manager.utils.anonymizer.greeting_patterns | default([], true) %}
          - {{ pattern }}
          {%- endfor %}
        signoff_patterns:
          {%- for pattern in data_manager.utils.anonymizer.signoff_patterns | default([], true) %}
          - {{ pattern }}
          {%- endfor %}
        email_pattern: {{ data_manager.utils.anonymizer.email_pattern | default('', true) }}
        username_pattern: {{ data_manager.utils.anonymizer.username_pattern | default('', true) }}

archi:
  pipelines: {{ archi.pipelines | default(['QAPipeline'], true) }}
  agent_description: {{ archi.agent_description | default('No description provided', true) }}
  pipeline_map:
    QAPipeline:
      max_tokens: {{ archi.pipeline_map.QAPipeline.max_tokens | default(10000, true) }}
      prompts:
        required:
          condense_prompt: {% if archi.pipeline_map.QAPipeline.prompts.required.condense_prompt %}"{{ archi.pipeline_map.QAPipeline.prompts.required.condense_prompt }}"{% else %}null{% endif %}
          chat_prompt: {% if archi.pipeline_map.QAPipeline.prompts.required.chat_prompt %}"{{ archi.pipeline_map.QAPipeline.prompts.required.chat_prompt }}"{% else %}null{% endif %}
      models:
        required:
          condense_model: {{ archi.pipeline_map.QAPipeline.models.required.condense_model | default('DumbLLM', true) }}
          chat_model: {{ archi.pipeline_map.QAPipeline.models.required.chat_model | default('DumbLLM', true) }}
    GradingPipeline:
      max_tokens: {{ archi.pipeline_map.GradingPipeline.max_tokens | default(10000, true) }}
      prompts:
        required:
          final_grade_prompt: {% if archi.pipeline_map.GradingPipeline.prompts.required.final_grade_prompt %}"{{ archi.pipeline_map.GradingPipeline.prompts.required.final_grade_prompt }}"{% else %}null{% endif %}
        optional:
          summary_prompt: {% if archi.pipeline_map.GradingPipeline.prompts.optional.summary_prompt %}"{{ archi.pipeline_map.GradingPipeline.prompts.optional.summary_prompt }}"{% else %}null{% endif %}
          analysis_prompt: {% if archi.pipeline_map.GradingPipeline.prompts.optional.analysis_prompt %}"{{ archi.pipeline_map.GradingPipeline.prompts.optional.analysis_prompt }}"{% else %}null{% endif %}
      models:
        required:
          final_grade_model: {{ archi.pipeline_map.GradingPipeline.models.required.final_grade_model | default('HuggingFaceOpenLLM', true) }}
        optional:
          summary_model: {{ archi.pipeline_map.GradingPipeline.models.optional.summary_model | default('HuggingFaceOpenLLM', true) }}
          analysis_model: {{ archi.pipeline_map.GradingPipeline.models.optional.analysis_model | default('HuggingFaceOpenLLM', true) }}
    ImageProcessingPipeline:
      max_tokens: {{ archi.pipeline_map.ImageProcessingPipeline.max_tokens | default(10000, true) }}
      prompts:
        required:
          image_processing_prompt: {% if archi.pipeline_map.ImageProcessingPipeline.prompts.required.image_processing_prompt %}"{{ archi.pipeline_map.ImageProcessingPipeline.prompts.required.image_processing_prompt }}"{% else %}null{% endif %}
      models:
        required:
          image_processing_model: {{ archi.pipeline_map.ImageProcessingPipeline.models.required.image_processing_model | default('HuggingFaceImageLLM', true) }}
    CMSCompOpsAgent:
      recursion_limit: {{ archi.pipeline_map.CMSCompOpsAgent.recursion_limit | default(100, true) }}
      prompts:
        required:
          agent_prompt: {% if archi.pipeline_map.CMSCompOpsAgent.prompts.required.agent_prompt %}"{{ archi.pipeline_map.CMSCompOpsAgent.prompts.required.agent_prompt }}"{% else %}null{% endif %}
      models:
        required:
          agent_model: {{ archi.pipeline_map.CMSCompOpsAgent.models.required.agent_model | default('OllamaInterface', true) }}

  model_class_map:
    AnthropicLLM:
      class: AnthropicLLM
      kwargs:
        model_name: {{ a2rchi.model_class_map.AnthropicLLM.kwargs.model_name | default('claude-3-opus-20240229', true) }}
        temperature: {{ a2rchi.model_class_map.AnthropicLLM.kwargs.temperature | default(1, true) }}
    OpenAILLM:
      class: OpenAILLM
      kwargs:
        model_name: {{ a2rchi.model_class_map.OpenAILLM.kwargs.model_name | default('gpt-4o', true) }}
        temperature: {{ a2rchi.model_class_map.OpenAILLM.kwargs.temperature | default(1, true) }}
    DumbLLM:
      class: DumbLLM
      kwargs:
        sleep_time_mean: {{ archi.model_class_map.DumbLLM.kwargs.sleep_time_mean | default(3, true) }}
        filler: {{ archi.model_class_map.DumbLLM.kwargs.filler | default('I am a dummy LLM response.', true) }}
    LlamaLLM:
      class: LlamaLLM
      kwargs:
        base_model: {{ archi.model_class_map.LlamaLLM.kwargs.base_model | default("meta-llama/Llama-2-7b-chat-hf", true) }}
        peft_model: {{ archi.model_class_map.LlamaLLM.kwargs.peft_model | default("null", true) }}
        enable_salesforce_content_safety: {{ archi.model_class_map.LlamaLLM.kwargs.enable_salesforce_content_safety | default(false, false) }}
        quantization: {{ archi.model_class_map.LlamaLLM.kwargs.quantization | default(true, true) }}
        max_new_tokens: {{ archi.model_class_map.LlamaLLM.kwargs.max_new_tokens | default(4096, true) }}
        seed: {{ archi.model_class_map.LlamaLLM.kwargs.seed | default("null", true) }}
        do_sample: {{ archi.model_class_map.LlamaLLM.kwargs.do_sample | default(true, true) }}
        min_length: {{ archi.model_class_map.LlamaLLM.kwargs.min_length | default("null", true) }}
        use_cache: {{ archi.model_class_map.LlamaLLM.kwargs.use_cache | default(true, true) }}
        top_p: {{ archi.model_class_map.LlamaLLM.kwargs.top_p | default(0.9, true) }}
        temperature: {{ archi.model_class_map.LlamaLLM.kwargs.temperature | default(0.6, true) }}
        top_k: {{ archi.model_class_map.LlamaLLM.kwargs.top_k | default(50, true) }}
        repetition_penalty: {{ archi.model_class_map.LlamaLLM.kwargs.repetition_penalty | default(1.0, true) }}
        length_penalty: {{ archi.model_class_map.LlamaLLM.kwargs.length_penalty | default(1, true) }}
        max_padding_length: {{ archi.model_class_map.LlamaLLM.kwargs.max_padding_length | default("null", true) }}
    HuggingFaceOpenLLM:
      class: HuggingFaceOpenLLM
      kwargs:
        base_model: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.base_model | default("Qwen/Qwen2.5-7B-Instruct-1M", true) }}
        peft_model: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.peft_model | default("null", true) }}
        enable_salesforce_content_safety: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.enable_salesforce_content_safety | default(false, false) }}
        quantization: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.quantization | default(true, true) }}
        max_new_tokens: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.max_new_tokens | default(4096, true) }}
        seed: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.seed | default("null", true) }}
        do_sample: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.do_sample | default(true, true) }}
        min_length: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.min_length | default("null", true) }}
        use_cache: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.use_cache | default(true, true) }}
        top_p: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.top_p | default(0.9, true) }}
        temperature: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.temperature | default(0.6, true) }}
        top_k: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.top_k | default(50, true) }}
        repetition_penalty: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.repetition_penalty | default(1.0, true) }}
        length_penalty: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.length_penalty | default(1, true) }}
        max_padding_length: {{ archi.model_class_map.HuggingFaceOpenLLM.kwargs.max_padding_length | default("null", true) }}
    HuggingFaceImageLLM:
      class: HuggingFaceImageLLM
      kwargs:
        base_model: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.base_model | default("Qwen/Qwen2.5-VL-7B-Instruct", true) }}
        quantization: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.quantization | default(true, true) }}
        min_pixels: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.min_pixels | default(175616, true) }}
        max_pixels: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.max_pixels | default(1003520, true) }}
        max_new_tokens: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.max_new_tokens | default(4096, true) }}
        seed: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.seed | default("null", true) }}
        do_sample: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.do_sample | default(false, false) }}
        min_length: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.min_length | default("null", true) }}
        use_cache: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.use_cache | default(true, true) }}
        top_k: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.top_k | default(50, true) }}
        repetition_penalty: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.repetition_penalty | default(1.0, true) }}
        length_penalty: {{ archi.model_class_map.HuggingFaceImageLLM.kwargs.length_penalty | default(1, true) }}
    VLLM:
      class: VLLM
      kwargs:
        base_model: {{ archi.model_class_map.VLLM.kwargs.base_model | default('Qwen/Qwen2.5-7B-Instruct-1M', true) }}
        seed: {{ archi.model_class_map.VLLM.kwargs.seed | default("null", true) }}
        enable_salesforce_content_safety: {{ archi.model_class_map.VLLM.kwargs.enable_salesforce_content_safety | default(false, false) }}
        max_new_tokens: {{ archi.model_class_map.VLLM.kwargs.max_new_tokens | default(4096, true) }}
        top_p: {{ archi.model_class_map.VLLM.kwargs.top_p | default(0.95, true) }}
        temperature: {{ archi.model_class_map.VLLM.kwargs.temperature | default(0.6, true) }}
        top_k: {{ archi.model_class_map.VLLM.kwargs.top_k | default(50, true) }}
        repetition_penalty: {{ archi.model_class_map.VLLM.kwargs.repetition_penalty | default(1.0, true) }}
        tensor_parallel_size: {{ archi.model_class_map.VLLM.kwargs.tensor_parallel_size | default(1, true) }}
        gpu_memory_utilization: {{ archi.model_class_map.VLLM.kwargs.gpu_memory_utilization | default(0.7, true) }}
        trust_remote_code: {{ archi.model_class_map.VLLM.kwargs.trust_remote_code | default(true, true) }}
        tokenizer_mode: {{ archi.model_class_map.VLLM.kwargs.tokenizer_mode | default("auto", true) }}
        max_model_len: {{ archi.model_class_map.VLLM.kwargs.max_model_len | default(10000, true) }}
    OllamaInterface:
      class: OllamaInterface
      kwargs:
        base_model: {{ archi.model_class_map.OllamaInterface.kwargs.base_model | default("gemma3", true) }}
        temperature: {{ archi.model_class_map.OllamaInterface.kwargs.temperature | default(1, true) }}
        max_tokens: {{ archi.model_class_map.OllamaInterface.kwargs.max_tokens | default(1000, true) }}
        url: {{ archi.model_class_map.OllamaInterface.kwargs.url | default("http://localhost:7870", true) }}
  chain_update_time: {{ archi.chain_update_time | default(10, true) }}
  mcp_servers: {{ archi.mcp_servers | default({}, true) }}

utils:
  sso: {{ utils.sso | default({}, true) }}
