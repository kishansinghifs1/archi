name: pr_preview_config

services:
  postgres:
    port: 3456
  chat_app:
    pipeline: CMSCompOpsAgent
    port: 2786
    external_port: 2786
    trained_on: "Dummy data for preview"
  # Vector storage uses PostgreSQL with pgvector (only supported backend)
  data_manager:
    port: 4242
    external_port: 4242
    auth:
      enabled: false

data_manager:
  embedding_name: HuggingFaceEmbeddings
  embedding_class_map:
    HuggingFaceEmbeddings:
      class: HuggingFaceEmbeddings
      kwargs:
        model_name: sentence-transformers/all-MiniLM-L6-v2
        model_kwargs:
          device: cpu
        encode_kwargs:
          normalize_embeddings: true
      similarity_score_reference: 10
  # PostgreSQL with pgvector is the only supported vector backend
  use_hybrid_search: true
  sources:
    links:
      enabled: false
    local_files:
      paths:
        - tests/smoke/seed.txt

archi:
  pipelines: ['CMSCompOpsAgent']
  providers:
    local:
      enabled: true
      base_url: http://localhost:7870  # Ollama endpoint with scheme
      mode: ollama
      default_model: "qwen3:32b"
      models:
        - "qwen3:32b"
  pipeline_map:
    CMSCompOpsAgent:
      prompts:
        required:
          agent_prompt: tests/pr_preview_config/agent.prompt
      models:
        required:
          agent_model: local/qwen3:32b